{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_keyframes(video_path, num_snippets=6, frames_per_snippet=16, augmentation=True):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "\n",
    "    # Initialize an array to store keyframes\n",
    "    snippets = []\n",
    "    for i in range(num_snippets):\n",
    "        # Calculate the start and end time for the snippet\n",
    "        start_time = duration * (i / num_snippets)\n",
    "        end_time = duration * ((i + 1) / num_snippets)\n",
    "\n",
    "        # Uniformly sample time points within the snippet interval\n",
    "        keyframe_time = np.linspace(start_time, end_time, frames_per_snippet)\n",
    "\n",
    "        keyframes = []\n",
    "        for j in range(frames_per_snippet):\n",
    "            # Read the frame at the selected time\n",
    "            frame_index = min(int(keyframe_time[j]*fps), total_frames - 2)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Perform data augmentation if specified\n",
    "            if augmentation:\n",
    "                # Apply random cropping\n",
    "                h, w, _ = frame.shape\n",
    "                crop_start_x = np.random.randint(0, w // 4)\n",
    "                crop_start_y = np.random.randint(0, h // 4)\n",
    "                frame = frame[crop_start_y:crop_start_y + 3 * h // 4, crop_start_x:crop_start_x + 3 * w // 4, :]\n",
    "\n",
    "                # Apply horizontal flipping\n",
    "                if np.random.rand() > 0.5:\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "\n",
    "                # Adjust brightness\n",
    "                alpha = 1.0 + np.random.uniform(-0.2, 0.2)\n",
    "                frame = np.clip(alpha * frame, 0, 255).astype(np.uint8)\n",
    "\n",
    "            # Append the keyframe to the list\n",
    "            keyframes.append(frame)\n",
    "        snippets.append(keyframes)\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Convert the list of keyframes to a NumPy array\n",
    "    snippets = np.array(snippets)\n",
    "\n",
    "    return snippets\n",
    "\n",
    "def process_videos(input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Process each video in the input folder\n",
    "    for video_filename in os.listdir(input_folder):\n",
    "        if video_filename.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(input_folder, video_filename)\n",
    "            \n",
    "            # Extract keyframes from the video\n",
    "            snippets = extract_keyframes(video_path)\n",
    "\n",
    "            # Save keyframes as images in the output folder\n",
    "            for i, snippet in enumerate(snippets):\n",
    "                for j, frame in enumerate(snippet):\n",
    "                    if j<9:\n",
    "                        image_filename = f'{os.path.splitext(video_filename)[0]}-0{i+1}-0{j+1}.png'\n",
    "                    else:\n",
    "                        image_filename = f'{os.path.splitext(video_filename)[0]}-0{i+1}-{j+1}.png'\n",
    "                    image_path = os.path.join(output_folder, image_filename)\n",
    "                    cv2.imwrite(image_path, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "input_folder_path = 'Single_Actor_01'\n",
    "output_folder_path = 'Single_Image_01'\n",
    "process_videos(input_folder_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv1x1x1(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = conv3x3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layers,\n",
    "                 block_inplanes,\n",
    "                 conv1_t_size=7,\n",
    "                 conv1_t_stride=1,\n",
    "                 no_max_pool = False,\n",
    "                 shortcut_type='B',\n",
    "                 widen_factor=1.0,\n",
    "                 n_classes=400):\n",
    "        super().__init__()\n",
    "\n",
    "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
    "\n",
    "        self.in_planes = block_inplanes[0]\n",
    "        self.no_max_pool = no_max_pool\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3,\n",
    "                               self.in_planes,\n",
    "                               kernel_size=(conv1_t_size, 7, 7),\n",
    "                               stride=(conv1_t_stride, 2, 2),\n",
    "                               padding=(conv1_t_size // 2, 3, 3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n",
    "                                       shortcut_type)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       block_inplanes[1],\n",
    "                                       layers[1],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       block_inplanes[2],\n",
    "                                       layers[2],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       block_inplanes[3],\n",
    "                                       layers[3],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x, planes, stride):\n",
    "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
    "                                out.size(3), out.size(4))\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(self._downsample_basic_block,\n",
    "                                     planes=planes * block.expansion,\n",
    "                                     stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(in_planes=self.in_planes,\n",
    "                  planes=planes,\n",
    "                  stride=stride,\n",
    "                  downsample=downsample))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Start\")\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        print(\"After conv1, bn1, relu1\")\n",
    "        print(x.shape)\n",
    "        if not self.no_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "        print(\"After maxpool\")\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        print('After layer1')\n",
    "        print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        print('After layer2')\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print('After layer3')\n",
    "        print(x.shape)\n",
    "        x = self.layer4(x)\n",
    "        print('After layer4')\n",
    "        print(x.shape)\n",
    "        # print(\"Before avg pooling\")\n",
    "        # print(x.shape)\n",
    "        # x = self.avgpool(x)\n",
    "        # print(\"After avg pooling\")\n",
    "        # print(x.shape)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # print(\"After view\")\n",
    "        # print(x.shape)\n",
    "        # x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SpatialAveragePooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAveragePooling, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #dimension of x --> N x m x s\n",
    "        pooled = torch.mean(x, dim=2)\n",
    "        return pooled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 16, 3, 256, 256])\n",
      "torch.Size([6, 3, 16, 256, 256])\n",
      "Start\n",
      "torch.Size([6, 3, 16, 256, 256])\n",
      "After conv1, bn1, relu1\n",
      "torch.Size([6, 64, 16, 128, 128])\n",
      "After maxpool\n",
      "torch.Size([6, 64, 8, 64, 64])\n",
      "After layer1\n",
      "torch.Size([6, 256, 8, 64, 64])\n",
      "After layer2\n",
      "torch.Size([6, 512, 4, 32, 32])\n",
      "After layer3\n",
      "torch.Size([6, 1024, 2, 16, 16])\n",
      "After layer4\n",
      "torch.Size([6, 2048, 1, 8, 8])\n",
      "torch.Size([6, 2048, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models \n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "model_path = 'resnet_101_kinetics.pth'\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "resnet_101 = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes())\n",
    "if 'module.' in list(checkpoint['state_dict'].keys())[0]:\n",
    "    # Remove the 'module.' prefix from keys\n",
    "    new_state_dict = {k.replace('module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "\n",
    "    # Update the model's state dictionary\n",
    "    resnet_101.load_state_dict(new_state_dict, strict = False)\n",
    "else:\n",
    "    # If the 'module.' prefix is not present, load the state dictionary directly\n",
    "    resnet_101.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "folder_path = \"Single_Image_01/01-02-01-01-01-01-01-\"\n",
    "image_size = (256,256)\n",
    "\n",
    "def load_images_and_create_snippets(folder_path, image_size, snippet_size = 16, num_snippets = 6):\n",
    "    snippets = []\n",
    "    for i in range(1, num_snippets + 1):\n",
    "        snippet = []\n",
    "        for j in range(1, snippet_size + 1):\n",
    "            image_name = f\"{i:02d}-{j:02d}.png\"  # Format image name\n",
    "            # image_path = os.path.join(folder_path, image_name)\n",
    "            image_path = folder_path +image_name\n",
    "            image = Image.open(image_path).resize(image_size)\n",
    "            image_tensor = torch.tensor([list(image.getdata())], dtype=torch.float32).view(3, *image_size)\n",
    "            snippet.append(image_tensor)\n",
    "        snippets.append(torch.stack(snippet))\n",
    "    return torch.stack(snippets)\n",
    "\n",
    "tensor_data = load_images_and_create_snippets(folder_path, image_size)\n",
    "print(tensor_data.shape)  # Should print: torch.Size([6, 16, 3, 224, 224])\n",
    "tensor_data = tensor_data.transpose(1,2)\n",
    "# tensor_data = tensor_data.unsqueeze(0)\n",
    "# tensor_data = tensor_data.transpose(1,3)\n",
    "# tensor_data = tensor_data.transpose(1,2)\n",
    "print(tensor_data.shape)\n",
    "output = resnet_101(tensor_data)\n",
    "print(output.shape)\n",
    "# expected [1,1024,1,16,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten h and w using einops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
